

%\section{Constraints}
%The constraints in this project could fall into two groups. The first constraint is related to the limitation on laboratory conditions \cite{Connor2018BiometricFeatures}. In real-world circumstances, many situations such as walking speed, clothing, footwear, and load carriage could affect our results, whereas our datasets could cover some of these real-world conditions. For example, except for the walking speed and footwear, both datasets do not have useful information for other real-world situations. Consequently, our results are optimistically biased. Table \ref{tab:1_vul} indicates some inhibiting factors. 

%Another significant limitation in the Stepscan dataset is the lack of relative footprint location. The dataset included only aligned and segmented footprint images. The location of samples concerning each other is unknown. This information could play a significant role in predicting the location of future footsteps. 

%\begin{center}
%	\begin{table}[!t]
%	\caption{Some inhibiting factors in gait recognition.}
%	\label{tab:1_vul}
%	\hspace{3em}
%	\setlength\extrarowheight{-2pt}
%	\input{tables/project/1_vul.tex}
%	\end{table}
%\end{center}
 

\section{Remaining Work}

In recent years, improving the computational process of computers and other benefits of \gls{dnn} have caused many researchers (like \cite{IsmailFawaz2019DeepReview} and \cite{Costilla-Reyes2018DeepSensors}) to move towards \gls{dnn} for the classification of time series data. Therefore, these algorithms will review in this project.

Since the entire time series considered for extracting features, we had one value for each feature. For instance, the algorithm returned a global maximum as a Max feature while local maximums could be good features. As a result, it would be a good idea to analyze different parts of each time-series signal for extracting handcraft features. In other words, since each signal includes several stages of the walking cycle, features should be extracted according to these periods.   

Cropping heel or toe area in video before extracting features could help separate features based on the walking stages (pressure area). In this idea, each video will divided into N sub-area and then for each region, we extract features. 

Due to using the aligned video, we could consider some pixels over time as 2D signals. Although our features space increased rapidly, we could put a threshold on variance and energy of time-series signals for controlling features space. 

In addition, it had better to split the dataset into left and right footprints for exploring the effects of extracted features on classifier accuracy. 

 
Furthermore, this research will be implemented in python, and the source codes are available on the GitHub repository \cite{SKazemii/EE6563}. 

