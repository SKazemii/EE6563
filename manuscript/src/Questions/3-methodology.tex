\section{Literature Review}

%\subsection{The subsection also appears in the bookmarks}
DARPA, the Defense Advanced Research Projects Agency of the USA, started to research gait recognition by vision data in the early 2000s \cite{Connor2018BiometricFeatures}. Besides vision data \cite{Chen2006GaitModel}, some studies have instead used accelerometry from smartphones \cite{Mantyjarvi2005IdentifyingAccelerometers}, audio \cite{Geiger2013Gait-basedFeatures}, and underfoot pressures data \cite{Nakajima2000Footprint-BasedRecognition}. 







Addlesee in \cite{Addlesee1997TheFloor} used a new sensor (Active floor) for the first investigations into footprint recognition. This sensor was a square carpet tile maintained at the corners by some load cells and supplied the \gls{grf}. Orr and Abowd \cite{Orr2000TheTracking} extracted ten temporal features from the \gls{grf} curve. 

Moustakidis et al. \cite{Moustakidis2008SubjectSignals} extracted temporal features from the wavelet decomposition of \gls{grf} and then applied a kernel-based support vector machine. These studies have limitations in terms of the small sample sizes used for classification (e.g., 15 \cite{Orr2000TheTracking}, 10 \cite{Moustakidis2008SubjectSignals}, and 15 \cite{MiddletonARecognition}), and moderate classification rates ($CR < 90\%$).

Pataky in \cite{Pataky2012GaitIndividuals} could achieve a 99.6\% classification rate in a 104-participant dataset. This result was based on spatial alignment and automated dimensionality reduction. He used a template image that was made in \cite{Pataky2011AnEvaluation}. Pataky named this template the Munster-104 template.

In 2015, Cantoral-Ceballos \cite{Cantoral-Ceballos2015IntelligentEnvironments} introduced an intelligent carpet system. This carpet system (iMAGiMAT) worked based on the deformation of 116 distributed \gls{pof}. So that applying pressure to this system would change the intensity of the transmitted light. Thus the nature of the output of this sensor is time-series data.
 
Costilla-Reyes et al. \cite{Costilla-Reyes2016TemporalSystem} extracted five features directly from raw data of the iMAGiMAT sensor. They implemented 14 various machine learning methods for classification. The best result belonged to the Random Forest model with a validation score of $90.84 \pm 2.46\%$. 

Later, they in \cite{Costilla-Reyes2018DeepSensors} used an end-to-end convolutional neural network to extract Spatio-temporal features automatically. This technique increased their score by about 7 percent.

Barandas et al. in \cite{Barandas2020TSFEL:Library} introduced a Python package entitled Time Series Feature Extraction Library (TSFEL). This Python package could compute more than 60 different features from the time-series data.



\section{Features Extraction and Selection}

As we mentioned before, our goal is to develop a model for
classification. For this classification task, we use about $128$ features in four categories. These features set are explained briefly here and more details about them can be found in Appendix I. After extracting features from each time series, some of these features that were unneeded, irrelevant and redundant were eliminated. Feature selection causes the complexity of the model to reduce. 

\subsection{Temporal Features}
The first set of features that extracted is temporal features. features like mean, median, Area under the curve fall into this group. 


\subsection{statistical Features}


\subsection{spectral Features}


\subsection{Temporal Features}




index-specific while the rest are general economic variables and
are replicated for every index in the data set. This rich set of variables could be categorized in eight different groups that are primitive variables, technical indicators, world stock market indices, the
exchange rate of U.S. dollar to the other currencies, commodities,
data from big companies of the U.S. markets, future contracts, and
other useful variables. Some of these variables are important as
they represent mechanisms that naturally affect the stock markets,
directly or indirectly. Some other variables, on the other hand, are
useful as they provide clues or signs that can help the system to
predict the short-term future of the markets, even if they do not
represent causal relations. We briefly explain different groups of
our variable set here and more details about them can be found in
Appendix I.
Primitive variables: Close price and day of the week for which
the prediction is supposed to be made are primitive variables used
in this work.
Technical indicators: Technical analysts use technical indicators
which are extracted from historical data of stocks prices and trading information to analyze short-term movement of prices.




In this section, we describe the extracted features that are used to classify the models, including datasets, parameters of the networks,
evaluation methodology and baseline algorithms. Then, the evaluation results are reported.
6.1. Data gathering and preparation
The datasets used in this work include daily direction of the
close of S&P 500 index, NASDAQ Composite, Dow Jones Industrial
Average, NYSE Composite, and RUSSELL 2000. Each sample has 82
variables that already have been explained and its assigned label
is determined according to the Eq. (5), where closet refers to the
closing price at day t It is worth mentioning that for each index
only technical indicators and primitive variables are unique and
the other variables, like big U.S. companies or price of commodities, are common between different indices.